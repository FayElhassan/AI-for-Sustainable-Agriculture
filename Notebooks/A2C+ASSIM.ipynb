{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ztjSsDRDifq_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# import random\n",
        "# random.seed(42)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9EpI9SHiZ3H",
        "outputId": "e252ac5a-a97e-44ba-b3cf-9a32d1b8e25a"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "class ASACRLEnv(gym.Env):\n",
        "    def __init__(self,observations,actions,action_parameter,action_space):\n",
        "        \"\"\"initialise action space, observation space & load data\"\"\"\n",
        "        self.action_parameter = action_parameter\n",
        "        self.action_space = gym.spaces.Discrete(len(action_space))  # Use Discrete action space\n",
        "        self.observations = observations\n",
        "        self.actions = actions\n",
        "        self.index=0\n",
        "        self.teamindex=0\n",
        "        obs_min = np.min(self.observations[self.teamindex]).values\n",
        "        obs_max = np.max(self.observations[self.teamindex]).values\n",
        "\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=obs_min,\n",
        "            high=obs_max,\n",
        "            shape=self.observations[self.teamindex].iloc[0].shape,\n",
        "            dtype=np.float32)\n",
        "        self.curr_obs=self.observations[self.teamindex].iloc[self.index]\n",
        "        self.next_obs=self.curr_obs=self.observations[self.teamindex].iloc[self.index+1]\n",
        "        self.curr_reward=0\n",
        "        self.ep_reward=0\n",
        "        self.interval=action_space[1]-action_space[0]\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        self.reward = self.rewardfunc(action)\n",
        "        self.ep_reward += self.reward\n",
        "        self.index += 1\n",
        "        cur_obs = self.curr_obs\n",
        "        next_obs = self.next_obs\n",
        "        done = False  # Set done to False by default\n",
        "        if self.index >= len(self.observations[self.teamindex]) - 2:\n",
        "            self.reset()\n",
        "            done = True  # Set done to True when the episode is finished\n",
        "            return self.curr_obs, self.reward, done, {}  # Return the additional info as an empty dictionary\n",
        "        self.curr_obs = self.observations[self.teamindex].iloc[self.index]\n",
        "        self.next_obs = self.curr_obs = self.observations[self.teamindex].iloc[self.index + 1]\n",
        "        return self.curr_obs, self.reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        set index to 0 and increment team index by 1 if greater than 4 go back to 0\n",
        "        \"\"\"\n",
        "        self.teamindex+=1\n",
        "        if self.teamindex>=5:\n",
        "            self.teamindex=0\n",
        "        self.index=0\n",
        "        self.observation_space=self.observations[self.teamindex].iloc[0].shape\n",
        "        self.curr_obs=self.observations[self.teamindex].iloc[self.index]\n",
        "        self.next_obs=self.curr_obs=self.observations[self.teamindex].iloc[self.index+1]\n",
        "        self.curr_reward=0\n",
        "        self.ep_reward=0\n",
        "        return self.curr_obs\n",
        "    def rewardfunc(self, action):\n",
        "        # estimated_action = self.estimate_closest_as(self.actions[self.teamindex][self.action_parameter][self.index])\n",
        "        if action == self.estimate_closest_as(self.actions[self.teamindex][self.action_parameter][self.index]):\n",
        "            return 100\n",
        "        else:\n",
        "            return -1 * abs(action - self.estimate_closest_as(self.actions[self.teamindex][self.action_parameter][self.index]))\n",
        "\n",
        "\n",
        "#             return -1*abs(self.action_space[action]-self.actions[self.teamindex][\"assim_sp\"][self.index])\n",
        "\n",
        "    def estimate_closest_as(self, value):\n",
        "        try:\n",
        "            closest_action_index = int(value / self.interval)\n",
        "            closest_action_index = min(closest_action_index, self.action_space.n - 1)\n",
        "        except:\n",
        "            closest_action_index = self.action_space.n - 1\n",
        "        return closest_action_index\n",
        "\n",
        "\n",
        "\n",
        "    def resetinit(self):\n",
        "        self.teamindex=0\n",
        "        self.index=0\n",
        "        self.observation_space=self.observations[self.teamindex].iloc[0].shape\n",
        "        self.curr_obs=self.observations[self.teamindex].iloc[self.index]\n",
        "        self.next_obs=self.curr_obs=self.observations[self.teamindex].iloc[self.index+1]\n",
        "        self.curr_reward=0\n",
        "        self.ep_reward=0\n",
        "        return self.curr_obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2P4Vis0NiUnd"
      },
      "outputs": [],
      "source": [
        "with open('/Users/faymajidelhassan/Downloads/ASAC_2023/observations.pickle', 'rb') as handle:\n",
        "    obs = pickle.load(handle)\n",
        "with open('/Users/faymajidelhassan/Downloads/ASAC_2023/actions.pickle', 'rb') as handle:\n",
        "    actions = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CM3zus5_-4a",
        "outputId": "6a427950-5e1a-4e4c-cb4c-78a1e3650fe5"
      },
      "outputs": [],
      "source": [
        "assim_rl_actionspace=np.linspace(0,100,21)\n",
        "discrete=list(range(len(assim_rl_actionspace)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n7KarM76OEK",
        "outputId": "8ce908ea-a75b-4f9d-8209-dcef359e8a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: shimmy in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from shimmy) (1.23.5)\n",
            "Requirement already satisfied: gymnasium>=0.27.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from shimmy) (0.28.1)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy) (4.4.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy) (0.0.4)\n",
            "Requirement already satisfied: stable_baselines3 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (2.0.0)\n",
            "Requirement already satisfied: gymnasium==0.28.1 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from stable_baselines3) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from stable_baselines3) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.11 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from stable_baselines3) (2.0.1)\n",
            "Requirement already satisfied: cloudpickle in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from stable_baselines3) (2.0.0)\n",
            "Requirement already satisfied: pandas in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from stable_baselines3) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from stable_baselines3) (3.7.0)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (4.4.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from gymnasium==0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (3.12.2)\n",
            "Requirement already satisfied: sympy in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (1.11.1)\n",
            "Requirement already satisfied: networkx in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (2.8.4)\n",
            "Requirement already satisfied: jinja2 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from torch>=1.11->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (22.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from pandas->stable_baselines3) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.11->stable_baselines3) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.11->stable_baselines3) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install shimmy\n",
        "!pip install stable_baselines3\n",
        "!pip install gymnasium\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmbtlxgqn0qu",
        "outputId": "14926557-e602-4902-bfa0-62a44e47dd27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "# Create an instance of your custom environment\n",
        "env = ASACRLEnv(obs, actions, \"assim_sp\", discrete)\n",
        "\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "LE-G2RqBDR-1",
        "outputId": "98901d88-431a-4bec-84e1-8899288b96d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-4:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/faymajidelhassan/anaconda3/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages/tensorboardX/event_file_writer.py\", line 208, in run\n",
            "    self._record_writer.write_event(data)\n",
            "  File \"/Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages/tensorboardX/event_file_writer.py\", line 58, in write_event\n",
            "    return self._write_serialized_event(event.SerializeToString())\n",
            "  File \"/Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages/tensorboardX/event_file_writer.py\", line 63, in _write_serialized_event\n",
            "    self._py_recordio_writer.write(event_str)\n",
            "  File \"/Users/faymajidelhassan/anaconda3/lib/python3.10/site-packages/tensorboardX/record_writer.py\", line 189, in write\n",
            "    w(data)\n",
            "OSError: [Errno 28] No space left on device\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m# Log information for TensorBoard\u001b[39;00m\n\u001b[1;32m     55\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mChosen Action\u001b[39m\u001b[39m'\u001b[39m, action, episode)\n\u001b[0;32m---> 56\u001b[0m writer\u001b[39m.\u001b[39;49madd_scalar(\u001b[39m'\u001b[39;49m\u001b[39mObserved State\u001b[39;49m\u001b[39m'\u001b[39;49m, np\u001b[39m.\u001b[39;49mmean(obs), episode)  \u001b[39m# You can customize how you log the state\u001b[39;00m\n\u001b[1;32m     57\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mReceived Reward\u001b[39m\u001b[39m'\u001b[39m, reward, episode)\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorboardX/writer.py:455\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, display_name, summary_description)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput value: \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m is not a scalar\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(scalar_value))\n\u001b[0;32m--> 455\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_file_writer()\u001b[39m.\u001b[39;49madd_summary(\n\u001b[1;32m    456\u001b[0m     scalar(tag, scalar_value, display_name, summary_description), global_step, walltime)\n\u001b[1;32m    457\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_comet_logger()\u001b[39m.\u001b[39mlog_metric(tag, display_name, scalar_value, global_step)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorboardX/writer.py:145\u001b[0m, in \u001b[0;36mFileWriter.add_summary\u001b[0;34m(self, summary, global_step, walltime)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Adds a `Summary` protocol buffer to the event file.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39mThis method wraps the provided summary in an `Event` protocol buffer\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39mand adds it to the event file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m    walltime (from time.time())\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m event \u001b[39m=\u001b[39m event_pb2\u001b[39m.\u001b[39mEvent(summary\u001b[39m=\u001b[39msummary)\n\u001b[0;32m--> 145\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_event(event, global_step, walltime)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorboardX/writer.py:130\u001b[0m, in \u001b[0;36mFileWriter.add_event\u001b[0;34m(self, event, step, walltime)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[39m# Make sure step is converted from numpy or other formats\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[39m# since protobuf might not convert depending on version\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     event\u001b[39m.\u001b[39mstep \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(step)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevent_writer\u001b[39m.\u001b[39;49madd_event(event)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorboardX/event_file_writer.py:139\u001b[0m, in \u001b[0;36mEventFileWriter.add_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Adds an event to the event file.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m  event: An `Event` protocol buffer.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_closed:\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_queue\u001b[39m.\u001b[39;49mput(event)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/queues.py:89\u001b[0m, in \u001b[0;36mQueue.put\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_closed:\n\u001b[1;32m     88\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQueue \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m is closed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sem\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m     90\u001b[0m     \u001b[39mraise\u001b[39;00m Full\n\u001b[1;32m     92\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_notempty:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from stable_baselines3 import A2C\n",
        "from tensorboardX import SummaryWriter  # Import the SummaryWriter for TensorBoard\n",
        "\n",
        "# Environment settings\n",
        "EPISODES = 1  # Number of episodes\n",
        "# Exploration settings\n",
        "epsilon = 1  # not a constant, going to be decayed\n",
        "EPSILON_DECAY = 0.99975\n",
        "MIN_EPSILON = 0.001\n",
        "\n",
        "# Stats settings\n",
        "AGGREGATE_STATS_EVERY = 500  # steps\n",
        "SAVE_MODEL_EVERY = 100\n",
        "MODEL_NAME = \"AGCRL_ASSIM_BINA2C\"\n",
        "MIN_REWARD = -5000\n",
        "\n",
        "\n",
        "# Create a PPO agent\n",
        "model = A2C(\"MlpPolicy\", env,learning_rate=0.003,\n",
        "            verbose=1)\n",
        "\n",
        "# Create a TensorBoard summary writer\n",
        "writer = SummaryWriter(log_dir='A2C_BreRUN')\n",
        "\n",
        "\n",
        "# Continuous training loop\n",
        "ep_rewards = []\n",
        "episode = 0\n",
        "while True:\n",
        "    episode += 1\n",
        "    episode_reward = 0\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        if np.random.random() > epsilon:\n",
        "            action, _ = model.predict(obs)\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "\n",
        "        # Assuming action is a scalar value\n",
        "        new_obs, reward, done, _ = env.step([action])\n",
        "\n",
        "        episode_reward += reward\n",
        "        obs = new_obs\n",
        "\n",
        "        # Log information for TensorBoard\n",
        "        writer.add_scalar('Chosen Action', action, episode)\n",
        "        writer.add_scalar('Observed State', np.mean(obs), episode)  # You can customize how you log the state\n",
        "        writer.add_scalar('Received Reward', reward, episode)\n",
        "\n",
        "        if done:\n",
        "            ep_rewards.append(episode_reward)\n",
        "\n",
        "            if epsilon > MIN_EPSILON:\n",
        "                epsilon *= EPSILON_DECAY\n",
        "                epsilon = max(MIN_EPSILON, epsilon)\n",
        "\n",
        "            if episode_reward >= MIN_REWARD and episode % SAVE_MODEL_EVERY == SAVE_MODEL_EVERY :\n",
        "                model.save(f'models/{MODEL_NAME}__ep_{episode}__reward_{float(episode_reward):.2f}.model')\n",
        "\n",
        "            model.learn(total_timesteps=1)\n",
        "\n",
        "            # Log metrics for TensorBoard\n",
        "            writer.add_scalar('Episode Reward', episode_reward, episode)\n",
        "            writer.add_scalar('Epsilon', epsilon, episode)\n",
        "\n",
        "# Close the TensorBoard writer (this line will never be reached in infinite loop)\n",
        "writer.close()\n",
        "\n",
        "# Plot results (same as before)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(ep_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Episode Reward')\n",
        "plt.title('Episode Rewards')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(acc_regret)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Accumulated Regret')\n",
        "plt.title('Accumulated Regret')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
